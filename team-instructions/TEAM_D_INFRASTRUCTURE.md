# ğŸ— ãƒãƒ¼ãƒ D - ã‚¤ãƒ³ãƒ•ãƒ©ãƒ»DevOps ãƒãƒ¼ãƒ æŒ‡ç¤ºæ›¸

## ğŸ¯ ãƒãƒ¼ãƒ æ¦‚è¦
**è²¬ä»»é ˜åŸŸ**: ã‚¯ãƒ©ã‚¦ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©ã€CI/CDã€ç›£è¦–ãƒ»é‹ç”¨ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°
**ä¸»è¦æŠ€è¡“**: AWS/Azure, Docker, Kubernetes, Terraform, GitHub Actions

## ğŸ“‹ ç¾åœ¨ã®çŠ¶æ³ã¨å®Œæˆåº¦

### âœ… å®Œæˆæ¸ˆã¿æ©Ÿèƒ½ï¼ˆ75%ï¼‰
- **ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒ** (`/docker-compose.dev.yml`) - PostgreSQL, Redis, MinIO, Elasticsearch
- **åŸºæœ¬Dockerè¨­å®š** (`/backend/Dockerfile`, `/frontend/Dockerfile`) - ãƒãƒ«ãƒã‚¹ãƒ†ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
- **é–‹ç™ºç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ** (`/start.sh`, `/stop.sh`, `/status.sh`) - ç’°å¢ƒç®¡ç†è‡ªå‹•åŒ–
- **ç’°å¢ƒå¤‰æ•°ç®¡ç†** (`.env.example`) - è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
- **åŸºæœ¬ç›£è¦–** - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- **ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åŸºç›¤** - HTTPSã€åŸºæœ¬èªè¨¼

### ğŸŸ¡ éƒ¨åˆ†å®Ÿè£…æ©Ÿèƒ½ï¼ˆ50%ï¼‰
- **CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** - GitHub Actions åŸºæœ¬è¨­å®šã®ã¿
- **æœ¬ç•ªç’°å¢ƒæ§‹æˆ** - è¨­è¨ˆå®Œäº†ã€ãƒ‡ãƒ—ãƒ­ã‚¤æœªå®Ÿè£…
- **ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ** - åŸºæœ¬ãƒ­ã‚°ã®ã¿ã€è©³ç´°ç›£è¦–æœªå®Ÿè£…
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚·ã‚¹ãƒ†ãƒ ** - æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ã¿

### âŒ æœªå®Ÿè£…æ©Ÿèƒ½
- **æœ¬æ ¼çš„ãªã‚¯ãƒ©ã‚¦ãƒ‰ãƒ‡ãƒ—ãƒ­ã‚¤**
- **Kubernetes ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**
- **åŒ…æ‹¬çš„ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆ**
- **è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**
- **ç½å®³å¾©æ—§ã‚·ã‚¹ãƒ†ãƒ **

## ğŸš€ å„ªå…ˆåº¦åˆ¥å®Ÿè£…ã‚¿ã‚¹ã‚¯

### ã€é«˜å„ªå…ˆåº¦ã€‘å³åº§ã«å®Ÿè£…ã™ã¹ãæ©Ÿèƒ½

#### 1. æœ¬ç•ªç’°å¢ƒã‚¯ãƒ©ã‚¦ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©æ§‹ç¯‰
```hcl
# ğŸ“ /infrastructure/terraform/main.tf
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# VPCæ§‹æˆ
resource "aws_vpc" "ai_subsidy_vpc" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true
  
  tags = {
    Name        = "ai-subsidy-vpc"
    Environment = var.environment
    Project     = "ai-subsidy-system"
  }
}

# EKS ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼
resource "aws_eks_cluster" "ai_subsidy_cluster" {
  name     = "ai-subsidy-${var.environment}"
  role_arn = aws_iam_role.eks_cluster_role.arn
  version  = "1.28"

  vpc_config {
    subnet_ids              = aws_subnet.private[*].id
    endpoint_private_access = true
    endpoint_public_access  = true
    public_access_cidrs    = ["0.0.0.0/0"]
  }

  encryption_config {
    provider {
      key_arn = aws_kms_key.eks_encryption.arn
    }
    resources = ["secrets"]
  }
}

# RDS PostgreSQL
resource "aws_rds_instance" "ai_subsidy_db" {
  identifier     = "ai-subsidy-${var.environment}"
  engine         = "postgres"
  engine_version = "15.4"
  instance_class = "db.t3.medium"
  
  allocated_storage     = 100
  max_allocated_storage = 1000
  storage_type         = "gp3"
  storage_encrypted    = true
  
  db_name  = "ai_subsidy_${var.environment}"
  username = var.db_username
  password = var.db_password
  
  backup_retention_period = 30
  backup_window          = "03:00-04:00"
  maintenance_window     = "sun:04:00-sun:05:00"
  
  multi_az               = var.environment == "production"
  publicly_accessible   = false
  vpc_security_group_ids = [aws_security_group.rds.id]
  db_subnet_group_name   = aws_db_subnet_group.main.name
  
  skip_final_snapshot = var.environment != "production"
  
  tags = {
    Name        = "ai-subsidy-db-${var.environment}"
    Environment = var.environment
  }
}

# ElastiCache Redis
resource "aws_elasticache_replication_group" "ai_subsidy_redis" {
  replication_group_id       = "ai-subsidy-${var.environment}"
  description                = "Redis cluster for AI Subsidy System"
  
  port                       = 6379
  parameter_group_name       = "default.redis7"
  node_type                  = "cache.t3.micro"
  num_cache_clusters         = var.environment == "production" ? 3 : 1
  
  at_rest_encryption_enabled = true
  transit_encryption_enabled = true
  auth_token                 = var.redis_auth_token
  
  subnet_group_name = aws_elasticache_subnet_group.main.name
  security_group_ids = [aws_security_group.redis.id]
  
  tags = {
    Name        = "ai-subsidy-redis-${var.environment}"
    Environment = var.environment
  }
}
```

#### 2. Kubernetes ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆ
```yaml
# ğŸ“ /kubernetes/deployments/backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ai-subsidy-backend
  namespace: ai-subsidy
  labels:
    app: ai-subsidy-backend
    version: v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ai-subsidy-backend
  template:
    metadata:
      labels:
        app: ai-subsidy-backend
        version: v1
    spec:
      containers:
      - name: backend
        image: ai-subsidy/backend:latest
        ports:
        - containerPort: 3001
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: database-secret
              key: url
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: redis-secret
              key: url
        - name: OPENAI_API_KEY
          valueFrom:
            secretKeyRef:
              name: ai-keys-secret
              key: openai-key
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /api/health
            port: 3001
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /api/health
            port: 3001
          initialDelaySeconds: 5
          periodSeconds: 5
      imagePullSecrets:
      - name: registry-secret

---
apiVersion: v1
kind: Service
metadata:
  name: ai-subsidy-backend-service
  namespace: ai-subsidy
spec:
  selector:
    app: ai-subsidy-backend
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3001
  type: ClusterIP

---
# Horizontal Pod Autoscaler
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ai-subsidy-backend-hpa
  namespace: ai-subsidy
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ai-subsidy-backend
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

#### 3. åŒ…æ‹¬çš„CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
```yaml
# ğŸ“ /.github/workflows/ci-cd-pipeline.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          
      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
          
  # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆãƒ»ãƒ“ãƒ«ãƒ‰
  frontend-ci:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./frontend
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: './frontend/package-lock.json'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run linting
        run: npm run lint
        
      - name: Run type checking
        run: npm run type-check
        
      - name: Run unit tests
        run: npm run test
        
      - name: Run E2E tests
        run: npm run test:e2e
        
      - name: Build application
        run: npm run build
        
      - name: Upload build artifacts
        uses: actions/upload-artifact@v3
        with:
          name: frontend-build
          path: ./frontend/.next/
          
  # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆãƒ»ãƒ“ãƒ«ãƒ‰
  backend-ci:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: ./backend
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: './backend/package-lock.json'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Run database migrations
        run: npx prisma migrate deploy
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          
      - name: Run unit tests
        run: npm run test
        
      - name: Run integration tests
        run: npm run test:integration
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379
          
      - name: Run security audit
        run: npm audit --audit-level moderate
        
  # Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰ãƒ»ãƒ—ãƒƒã‚·ãƒ¥
  build-and-push:
    needs: [security-scan, frontend-ci, backend-ci]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    strategy:
      matrix:
        component: [frontend, backend]
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        
      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.component }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}
            
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: ./${{ matrix.component }}
          platforms: linux/amd64,linux/arm64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
  # æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤
  deploy-production:
    needs: [build-and-push]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ap-northeast-1
          
      - name: Deploy to EKS
        run: |
          aws eks update-kubeconfig --region ap-northeast-1 --name ai-subsidy-production
          kubectl apply -f kubernetes/
          kubectl rollout restart deployment/ai-subsidy-frontend -n ai-subsidy
          kubectl rollout restart deployment/ai-subsidy-backend -n ai-subsidy
          kubectl rollout status deployment/ai-subsidy-frontend -n ai-subsidy
          kubectl rollout status deployment/ai-subsidy-backend -n ai-subsidy
```

### ã€ä¸­å„ªå…ˆåº¦ã€‘æ¬¡ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…

#### 4. åŒ…æ‹¬çš„ç›£è¦–ãƒ»ãƒ­ã‚°ã‚·ã‚¹ãƒ†ãƒ 
```yaml
# ğŸ“ /kubernetes/monitoring/prometheus-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: monitoring
data:
  prometheus.yml: |
    global:
      scrape_interval: 15s
      evaluation_interval: 15s
    
    rule_files:
      - "/etc/prometheus/rules/*.yml"
    
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093
    
    scrape_configs:
      # Kubernetes API server
      - job_name: 'kubernetes-apiservers'
        kubernetes_sd_configs:
        - role: endpoints
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
        - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
          action: keep
          regex: default;kubernetes;https
      
      # AI Subsidy Application
      - job_name: 'ai-subsidy-backend'
        kubernetes_sd_configs:
        - role: endpoints
          namespaces:
            names:
            - ai-subsidy
        relabel_configs:
        - source_labels: [__meta_kubernetes_service_name]
          action: keep
          regex: ai-subsidy-backend-service
        - source_labels: [__meta_kubernetes_endpoint_port_name]
          action: keep
          regex: metrics
      
      # Node Exporter
      - job_name: 'node-exporter'
        kubernetes_sd_configs:
        - role: node
        relabel_configs:
        - action: labelmap
          regex: __meta_kubernetes_node_label_(.+)
        - target_label: __address__
          replacement: kubernetes.default.svc:443
        - source_labels: [__meta_kubernetes_node_name]
          regex: (.+)
          target_label: __metrics_path__
          replacement: /api/v1/nodes/${1}/proxy/metrics
```

#### 5. ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
```yaml
# ğŸ“ /kubernetes/monitoring/alert-rules.yaml
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: ai-subsidy-alerts
  namespace: monitoring
spec:
  groups:
  - name: ai-subsidy.rules
    rules:
    # Application Health
    - alert: ApplicationDown
      expr: up{job="ai-subsidy-backend"} == 0
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "AI Subsidy application is down"
        description: "The AI Subsidy backend application has been down for more than 5 minutes"
    
    # High Response Time
    - alert: HighResponseTime
      expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="ai-subsidy-backend"}[5m])) > 2
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High response time detected"
        description: "95th percentile response time is {{ $value }}s"
    
    # High Error Rate
    - alert: HighErrorRate
      expr: rate(http_requests_total{job="ai-subsidy-backend",status=~"5.."}[5m]) / rate(http_requests_total{job="ai-subsidy-backend"}[5m]) > 0.1
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High error rate detected"
        description: "Error rate is {{ $value | humanizePercentage }}"
    
    # Database Connection Issues
    - alert: DatabaseConnectionFailure
      expr: increase(database_connections_failed_total[5m]) > 5
      for: 2m
      labels:
        severity: critical
      annotations:
        summary: "Database connection failures"
        description: "{{ $value }} database connection failures in the last 5 minutes"
    
    # AI Service Issues
    - alert: AIServiceHighLatency
      expr: histogram_quantile(0.95, rate(ai_request_duration_seconds_bucket[5m])) > 10
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "AI service high latency"
        description: "AI service 95th percentile latency is {{ $value }}s"
    
    # Resource Usage
    - alert: HighCPUUsage
      expr: (100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)) > 85
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "High CPU usage"
        description: "CPU usage is {{ $value }}%"
    
    - alert: HighMemoryUsage
      expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 90
      for: 5m
      labels:
        severity: critical
      annotations:
        summary: "High memory usage"
        description: "Memory usage is {{ $value }}%"
```

### ã€ä½å„ªå…ˆåº¦ã€‘å°†æ¥çš„ãªå®Ÿè£…

#### 6. ç½å®³å¾©æ—§ãƒ»äº‹æ¥­ç¶™ç¶šè¨ˆç”»
```bash
# ğŸ“ /scripts/disaster-recovery.sh
#!/bin/bash

# ç½å®³å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
# RTO: 30åˆ†, RPO: 5åˆ†

set -e

BACKUP_BUCKET="ai-subsidy-backups"
REGION="ap-northeast-1"
CLUSTER_NAME="ai-subsidy-production"

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©æ—§
restore_database() {
    echo "ğŸ”„ Starting database restoration..."
    
    # æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å–å¾—
    LATEST_BACKUP=$(aws rds describe-db-snapshots \
        --db-instance-identifier ai-subsidy-production \
        --snapshot-type manual \
        --query 'DBSnapshots[0].DBSnapshotIdentifier' \
        --output text)
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¾©å…ƒ
    aws rds restore-db-instance-from-db-snapshot \
        --db-instance-identifier ai-subsidy-recovery \
        --db-snapshot-identifier $LATEST_BACKUP \
        --db-instance-class db.t3.medium
        
    echo "âœ… Database restoration initiated"
}

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å¾©æ—§
restore_file_storage() {
    echo "ğŸ”„ Restoring file storage..."
    
    # S3åŒæœŸ
    aws s3 sync s3://$BACKUP_BUCKET/files/ s3://ai-subsidy-files-recovery/
    
    echo "âœ… File storage restored"
}

# Kuberneteså¾©æ—§
restore_kubernetes() {
    echo "ğŸ”„ Restoring Kubernetes services..."
    
    # kubeconfigæ›´æ–°
    aws eks update-kubeconfig --region $REGION --name $CLUSTER_NAME
    
    # ã‚µãƒ¼ãƒ“ã‚¹å¾©æ—§
    kubectl apply -f kubernetes/
    
    # ãƒãƒƒãƒ‰å†èµ·å‹•
    kubectl rollout restart deployment -n ai-subsidy
    
    echo "âœ… Kubernetes services restored"
}

# å¾©æ—§å®Ÿè¡Œ
main() {
    echo "ğŸš¨ Starting disaster recovery process..."
    
    restore_database &
    restore_file_storage &
    restore_kubernetes &
    
    wait
    
    echo "âœ… Disaster recovery completed"
    echo "ğŸ” Please verify all services are functioning correctly"
}

main "$@"
```

## ğŸ”§ é–‹ç™ºç’°å¢ƒå¼·åŒ–

### ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒæœ€é©åŒ–
```bash
# ğŸ“ /scripts/dev-setup.sh
#!/bin/bash

# é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
set -e

echo "ğŸš€ Setting up AI Subsidy development environment..."

# å¿…è¦ãƒ„ãƒ¼ãƒ«ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯
check_requirements() {
    echo "ğŸ“‹ Checking requirements..."
    
    command -v docker >/dev/null 2>&1 || { echo "âŒ Docker is required but not installed."; exit 1; }
    command -v docker-compose >/dev/null 2>&1 || { echo "âŒ Docker Compose is required but not installed."; exit 1; }
    command -v node >/dev/null 2>&1 || { echo "âŒ Node.js is required but not installed."; exit 1; }
    command -v git >/dev/null 2>&1 || { echo "âŒ Git is required but not installed."; exit 1; }
    
    echo "âœ… All requirements satisfied"
}

# ç’°å¢ƒå¤‰æ•°è¨­å®š
setup_environment() {
    echo "ğŸ”§ Setting up environment variables..."
    
    if [ ! -f .env ]; then
        cp .env.example .env
        echo "ğŸ“ Created .env file from template"
        echo "âš ï¸  Please update .env with your configuration"
    fi
}

# Dockerç’°å¢ƒæ§‹ç¯‰
setup_docker() {
    echo "ğŸ³ Setting up Docker environment..."
    
    # ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
    docker-compose -f docker-compose.dev.yml build
    
    # ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•
    docker-compose -f docker-compose.dev.yml up -d
    
    echo "âœ… Docker environment ready"
}

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
setup_database() {
    echo "ğŸ—„ï¸ Setting up database..."
    
    # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    cd backend
    npm install
    npx prisma migrate dev
    npx prisma db seed
    cd ..
    
    echo "âœ… Database initialized"
}

# ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç’°å¢ƒ
setup_frontend() {
    echo "ğŸ¨ Setting up frontend..."
    
    cd frontend
    npm install
    npm run build
    cd ..
    
    echo "âœ… Frontend ready"
}

# é–‹ç™ºãƒ„ãƒ¼ãƒ«è¨­å®š
setup_dev_tools() {
    echo "ğŸ› ï¸ Setting up development tools..."
    
    # Git hooks
    if [ ! -f .git/hooks/pre-commit ]; then
        echo "#!/bin/sh" > .git/hooks/pre-commit
        echo "npm run lint:check" >> .git/hooks/pre-commit
        chmod +x .git/hooks/pre-commit
    fi
    
    # VSCodeè¨­å®š
    mkdir -p .vscode
    cat > .vscode/settings.json << EOF
{
  "typescript.preferences.importModuleSpecifier": "relative",
  "editor.formatOnSave": true,
  "editor.codeActionsOnSave": {
    "source.fixAll.eslint": true
  },
  "tailwindCSS.includeLanguages": {
    "typescript": "javascript",
    "typescriptreact": "javascript"
  }
}
EOF
    
    echo "âœ… Development tools configured"
}

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
health_check() {
    echo "ğŸ” Running health check..."
    
    # ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•å¾…æ©Ÿ
    sleep 10
    
    # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    if curl -f http://localhost:3001/api/health > /dev/null 2>&1; then
        echo "âœ… Backend service is healthy"
    else
        echo "âŒ Backend service is not responding"
    fi
    
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚§ãƒƒã‚¯
    if curl -f http://localhost:3000 > /dev/null 2>&1; then
        echo "âœ… Frontend service is healthy"
    else
        echo "âŒ Frontend service is not responding"
    fi
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯
    if docker-compose -f docker-compose.dev.yml exec postgres pg_isready > /dev/null 2>&1; then
        echo "âœ… Database is ready"
    else
        echo "âŒ Database is not ready"
    fi
}

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
main() {
    check_requirements
    setup_environment
    setup_docker
    setup_database
    setup_frontend
    setup_dev_tools
    health_check
    
    echo ""
    echo "ğŸ‰ Development environment setup completed!"
    echo ""
    echo "ğŸ“ Available services:"
    echo "   Frontend:  http://localhost:3000"
    echo "   Backend:   http://localhost:3001"
    echo "   API Docs:  http://localhost:3001/api-docs"
    echo ""
    echo "ğŸ”§ Useful commands:"
    echo "   ./start.sh    - Start all services"
    echo "   ./stop.sh     - Stop all services"
    echo "   ./status.sh   - Check service status"
    echo "   ./logs.sh     - View service logs"
}

main "$@"
```

## ğŸ“Š ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
```json
{
  "dashboard": {
    "title": "AI Subsidy System Monitoring",
    "panels": [
      {
        "title": "Application Health",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"ai-subsidy-backend\"}",
            "legendFormat": "Backend Status"
          },
          {
            "expr": "up{job=\"ai-subsidy-frontend\"}",
            "legendFormat": "Frontend Status"
          }
        ]
      },
      {
        "title": "Request Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{job=\"ai-subsidy-backend\"}[5m])",
            "legendFormat": "Requests/sec"
          }
        ]
      },
      {
        "title": "Response Time",
        "type": "graph",
        "targets": [
          {
            "expr": "histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job=\"ai-subsidy-backend\"}[5m]))",
            "legendFormat": "95th percentile"
          },
          {
            "expr": "histogram_quantile(0.50, rate(http_request_duration_seconds_bucket{job=\"ai-subsidy-backend\"}[5m]))",
            "legendFormat": "50th percentile"
          }
        ]
      },
      {
        "title": "Error Rate",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(http_requests_total{job=\"ai-subsidy-backend\",status=~\"5..\"}[5m]) / rate(http_requests_total{job=\"ai-subsidy-backend\"}[5m])",
            "legendFormat": "Error Rate"
          }
        ]
      },
      {
        "title": "AI Service Metrics",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(ai_requests_total[5m])",
            "legendFormat": "AI Requests/sec"
          },
          {
            "expr": "histogram_quantile(0.95, rate(ai_request_duration_seconds_bucket[5m]))",
            "legendFormat": "AI Response Time (95th)"
          }
        ]
      },
      {
        "title": "Database Performance",
        "type": "graph",
        "targets": [
          {
            "expr": "rate(database_queries_total[5m])",
            "legendFormat": "Queries/sec"
          },
          {
            "expr": "database_connections_active",
            "legendFormat": "Active Connections"
          }
        ]
      },
      {
        "title": "Resource Usage",
        "type": "graph",
        "targets": [
          {
            "expr": "100 - (avg(irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100)",
            "legendFormat": "CPU Usage %"
          },
          {
            "expr": "(1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100",
            "legendFormat": "Memory Usage %"
          }
        ]
      }
    ]
  }
}
```

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³è‡ªå‹•åŒ–
```yaml
# ğŸ“ /.github/workflows/security-scan.yml
name: Security Scan

on:
  schedule:
    - cron: '0 2 * * *'  # æ¯æ—¥åˆå‰2æ™‚ã«å®Ÿè¡Œ
  workflow_dispatch:

jobs:
  vulnerability-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'
          
      - name: Upload to GitHub Security Tab
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'
          
  dependency-check:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run OWASP Dependency Check
        uses: dependency-check/Dependency-Check_Action@main
        with:
          project: 'ai-subsidy-system'
          path: '.'
          format: 'ALL'
          
  secret-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Run TruffleHog
        uses: trufflesecurity/trufflehog@main
        with:
          path: ./
          base: main
          head: HEAD
```

### ã‚³ãƒ³ãƒ—ãƒ©ã‚¤ã‚¢ãƒ³ã‚¹è¨­å®š
```yaml
# ğŸ“ /kubernetes/policies/network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: ai-subsidy-network-policy
  namespace: ai-subsidy
spec:
  podSelector:
    matchLabels:
      app: ai-subsidy-backend
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ai-subsidy
    - podSelector:
        matchLabels:
          app: ai-subsidy-frontend
    ports:
    - protocol: TCP
      port: 3001
  egress:
  - to:
    - namespaceSelector:
        matchLabels:
          name: kube-system
  - to: []
    ports:
    - protocol: TCP
      port: 5432  # PostgreSQL
    - protocol: TCP
      port: 6379  # Redis
    - protocol: TCP
      port: 443   # HTTPS
    - protocol: TCP
      port: 53    # DNS
    - protocol: UDP
      port: 53    # DNS
```

## ğŸ¤ ãƒãƒ¼ãƒ é€£æºãƒ»é‹ç”¨

### ä»–ãƒãƒ¼ãƒ ã¨ã®é€£æºã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
```bash
# ğŸ“ /scripts/team-coordination.sh

# ãƒãƒ¼ãƒ Aï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼‰ã¨ã®é€£æº
deploy_frontend() {
    echo "ğŸ¨ Deploying frontend updates..."
    
    # ç’°å¢ƒå¤‰æ•°æ³¨å…¥
    kubectl create configmap frontend-config \
        --from-env-file=frontend/.env.production \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ
    kubectl set image deployment/ai-subsidy-frontend \
        frontend=ghcr.io/ai-subsidy/frontend:$1 -n ai-subsidy
    
    # ãƒ­ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆç›£è¦–
    kubectl rollout status deployment/ai-subsidy-frontend -n ai-subsidy
}

# ãƒãƒ¼ãƒ Bï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰ã¨ã®é€£æº
deploy_backend() {
    echo "âš™ï¸ Deploying backend updates..."
    
    # ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆæ›´æ–°
    kubectl create secret generic backend-secrets \
        --from-env-file=backend/.env.production \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
    kubectl run migration-job-$(date +%s) \
        --image=ghcr.io/ai-subsidy/backend:$1 \
        --restart=Never \
        --rm -i --tty \
        --env-from=secretRef:backend-secrets \
        -- npx prisma migrate deploy
    
    # ãƒ‡ãƒ—ãƒ­ã‚¤å®Ÿè¡Œ
    kubectl set image deployment/ai-subsidy-backend \
        backend=ghcr.io/ai-subsidy/backend:$1 -n ai-subsidy
}

# ãƒãƒ¼ãƒ Cï¼ˆAIï¼‰ã¨ã®é€£æº
deploy_ai_services() {
    echo "ğŸ¤– Deploying AI service updates..."
    
    # AIè¨­å®šæ›´æ–°
    kubectl create configmap ai-config \
        --from-file=ai-engine/config/ \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # AIãƒ¯ãƒ¼ã‚«ãƒ¼æ›´æ–°
    kubectl set image deployment/ai-worker \
        ai-worker=ghcr.io/ai-subsidy/ai-engine:$1 -n ai-subsidy
}
```

### éšœå®³å¯¾å¿œãƒ—ãƒ­ã‚»ã‚¹
```bash
# ğŸ“ /scripts/incident-response.sh
#!/bin/bash

# ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
set -e

INCIDENT_LEVEL=$1  # critical, major, minor
COMPONENT=$2       # frontend, backend, database, ai

# ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥
notify_team() {
    local level=$1
    local component=$2
    local message=$3
    
    # Slacké€šçŸ¥
    curl -X POST $SLACK_WEBHOOK_URL \
        -H 'Content-type: application/json' \
        --data "{
            \"text\": \"ğŸš¨ $level incident detected in $component: $message\",
            \"channel\": \"#incidents\",
            \"username\": \"AlertBot\"
        }"
    
    # PagerDutyé€šçŸ¥ï¼ˆCritical ã®ã¿ï¼‰
    if [ "$level" = "critical" ]; then
        curl -X POST https://events.pagerduty.com/v2/enqueue \
            -H 'Content-Type: application/json' \
            -d "{
                \"routing_key\": \"$PAGERDUTY_ROUTING_KEY\",
                \"event_action\": \"trigger\",
                \"payload\": {
                    \"summary\": \"Critical incident in $component\",
                    \"severity\": \"critical\",
                    \"source\": \"ai-subsidy-system\"
                }
            }"
    fi
}

# è‡ªå‹•å¾©æ—§è©¦è¡Œ
auto_recovery() {
    local component=$1
    
    case $component in
        "frontend")
            kubectl rollout restart deployment/ai-subsidy-frontend -n ai-subsidy
            ;;
        "backend")
            kubectl rollout restart deployment/ai-subsidy-backend -n ai-subsidy
            ;;
        "database")
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ãƒªã‚»ãƒƒãƒˆ
            kubectl exec -it deployment/ai-subsidy-backend -n ai-subsidy -- \
                node -e "require('./scripts/reset-db-pool.js')"
            ;;
        "ai")
            kubectl rollout restart deployment/ai-worker -n ai-subsidy
            ;;
    esac
}

# è¨ºæ–­æƒ…å ±åé›†
collect_diagnostics() {
    local timestamp=$(date +%Y%m%d_%H%M%S)
    local output_dir="diagnostics_$timestamp"
    
    mkdir -p $output_dir
    
    # Kubernetesæƒ…å ±
    kubectl get pods -n ai-subsidy > $output_dir/pods.txt
    kubectl describe pods -n ai-subsidy > $output_dir/pod_details.txt
    kubectl logs -n ai-subsidy --all-containers=true > $output_dir/logs.txt
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æƒ…å ±
    curl -s "http://prometheus:9090/api/v1/query?query=up" > $output_dir/service_status.json
    
    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    tar -czf diagnostics_$timestamp.tar.gz $output_dir
    aws s3 cp diagnostics_$timestamp.tar.gz s3://ai-subsidy-diagnostics/
    
    echo "Diagnostics collected: s3://ai-subsidy-diagnostics/diagnostics_$timestamp.tar.gz"
}

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
main() {
    echo "ğŸš¨ Incident Response: $INCIDENT_LEVEL level incident in $COMPONENT"
    
    # é€šçŸ¥é€ä¿¡
    notify_team $INCIDENT_LEVEL $COMPONENT "Automated incident response initiated"
    
    # è¨ºæ–­æƒ…å ±åé›†
    collect_diagnostics
    
    # è‡ªå‹•å¾©æ—§è©¦è¡Œï¼ˆMinor/Major ã®ã¿ï¼‰
    if [ "$INCIDENT_LEVEL" != "critical" ]; then
        echo "ğŸ”„ Attempting automatic recovery..."
        auto_recovery $COMPONENT
        
        # å¾©æ—§ç¢ºèª
        sleep 60
        if kubectl get pods -n ai-subsidy | grep -q "Running"; then
            notify_team "info" $COMPONENT "Automatic recovery successful"
        else
            notify_team "warning" $COMPONENT "Automatic recovery failed - manual intervention required"
        fi
    else
        echo "âš ï¸ Critical incident - manual intervention required"
    fi
}

main "$@"
```

## ğŸ“š å­¦ç¿’ãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

### å¿…é ˆå­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹
- **Kubernetes Documentation**: https://kubernetes.io/docs/
- **AWS EKS Best Practices**: https://aws.github.io/aws-eks-best-practices/
- **Terraform Documentation**: https://www.terraform.io/docs
- **Prometheus Monitoring**: https://prometheus.io/docs/
- **Docker Best Practices**: https://docs.docker.com/develop/dev-best-practices/

### é‹ç”¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
```markdown
# ğŸ“ /docs/operations/README.md

# é‹ç”¨ã‚¬ã‚¤ãƒ‰

## æ—¥æ¬¡é‹ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèªï¼ˆkubectl get podsï¼‰
- [ ] ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèªï¼ˆGrafana ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼‰
- [ ] ãƒ­ã‚°ç¢ºèªï¼ˆCloudWatch/ELKï¼‰
- [ ] ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—çŠ¶æ…‹ç¢ºèª
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª

## é€±æ¬¡é‹ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
- [ ] ã‚³ã‚¹ãƒˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³å®Ÿè¡Œ
- [ ] ä¾å­˜é–¢ä¿‚æ›´æ–°ç¢ºèª
- [ ] ç½å®³å¾©æ—§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

## æœˆæ¬¡é‹ç”¨ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
- [ ] ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°è¦‹ç›´ã—
- [ ] ã‚¤ãƒ³ãƒ•ãƒ©ã‚³ã‚¹ãƒˆæœ€é©åŒ–
- [ ] ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒãƒªã‚·ãƒ¼è¦‹ç›´ã—
- [ ] ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šè¦‹ç›´ã—
- [ ] ç½å®³å¾©æ—§è¨ˆç”»æ›´æ–°
```

---

**ğŸ¯ æœ€çµ‚ç›®æ¨™**: 24/7ç¨¼åƒå¯èƒ½ãªã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§å®‰å…¨ãªã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºã‚°ãƒ¬ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ•ãƒ©ã‚’æ§‹ç¯‰ãƒ»é‹ç”¨ã™ã‚‹

**ğŸ“ ç·Šæ€¥é€£çµ¡**: ãƒãƒ¼ãƒ ãƒªãƒ¼ãƒ€ãƒ¼ï¼ˆSlack: @team-d-infraã€ã‚ªãƒ³ã‚³ãƒ¼ãƒ«: +81-XXX-XXXX-XXXXï¼‰