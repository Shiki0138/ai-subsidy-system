"""
AI ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ç‰ˆï¼‰
å¤–éƒ¨ä¾å­˜é–¢ä¿‚ãªã—ã§ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
"""

import pytest
import asyncio
import json
from unittest.mock import Mock, patch, AsyncMock, MagicMock
from datetime import datetime, timedelta
import sys
import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Any
from enum import Enum

# ãƒ¢ãƒƒã‚¯ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä½œæˆ
class MockOpenAI:
    def __init__(self, api_key):
        self.api_key = api_key
    
    class chat:
        class completions:
            @staticmethod
            async def create(**kwargs):
                mock_response = Mock()
                mock_response.choices = [Mock()]
                mock_response.choices[0].message.content = "ãƒ¢ãƒƒã‚¯ç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„"
                mock_response.choices[0].finish_reason = "stop"
                mock_response.model = "gpt-4"
                mock_response.usage = Mock()
                mock_response.usage.prompt_tokens = 100
                mock_response.usage.completion_tokens = 200
                mock_response.usage.total_tokens = 300
                mock_response.usage._asdict = lambda: {
                    'prompt_tokens': 100,
                    'completion_tokens': 200,
                    'total_tokens': 300
                }
                return mock_response

class MockAnthropic:
    def __init__(self, api_key):
        self.api_key = api_key
    
    class messages:
        @staticmethod
        async def create(**kwargs):
            mock_response = Mock()
            mock_response.content = [Mock()]
            mock_response.content[0].text = "ãƒ¢ãƒƒã‚¯ç”Ÿæˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ï¼ˆAnthropicï¼‰"
            mock_response.model = "claude-3-5-sonnet"
            mock_response.usage = Mock()
            mock_response.usage.input_tokens = 150
            mock_response.usage.output_tokens = 250
            mock_response.stop_reason = "end_turn"
            return mock_response

# åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹å®šç¾©
class AIProvider(Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    HYBRID = "hybrid"

@dataclass
class AIRequest:
    request_id: str
    user_id: str
    task_type: str
    input_data: Dict
    options: Optional[Dict] = None
    timestamp: datetime = None

    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()

@dataclass
class AIResponse:
    request_id: str
    success: bool
    content: Optional[str] = None
    error: Optional[str] = None
    metadata: Dict = None
    provider: Optional[str] = None
    processing_time: float = 0
    quality_score: float = 0
    confidence_score: float = 0
    cost: float = 0

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

# ãƒ¢ãƒƒã‚¯ç‰ˆ EnhancedAIService
class MockEnhancedAIService:
    def __init__(self):
        self.openai_client = MockOpenAI("mock-key")
        self.anthropic_client = MockAnthropic("mock-key")
    
    async def generate_business_plan(
        self, 
        company_data: Dict,
        subsidy_type: str,
        custom_requirements: Optional[List[str]] = None,
        provider: AIProvider = AIProvider.HYBRID
    ) -> AIResponse:
        # ãƒ¢ãƒƒã‚¯äº‹æ¥­è¨ˆç”»æ›¸ç”Ÿæˆ
        await asyncio.sleep(0.1)  # å‡¦ç†æ™‚é–“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        
        business_plan = {
            "companyOverview": f"{company_data.get('name', 'ä¼æ¥­å')}ã¯{company_data.get('industry', 'æ¥­ç•Œ')}ã§ã®äº‹æ¥­ã‚’å±•é–‹",
            "projectDescription": f"{subsidy_type}ã‚’æ´»ç”¨ã—ãŸDXãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ",
            "marketAnalysis": "å¸‚å ´åˆ†æçµæœ",
            "businessPlan": "è©³ç´°ãªäº‹æ¥­è¨ˆç”»",
            "expectedOutcomes": "æœŸå¾…ã•ã‚Œã‚‹æˆæœ",
            "budgetPlan": "äºˆç®—è¨ˆç”»",
            "implementation": "å®Ÿæ–½ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«"
        }
        
        return AIResponse(
            request_id=f"bp_{int(datetime.now().timestamp())}",
            success=True,
            content=json.dumps(business_plan, ensure_ascii=False),
            provider=provider.value,
            processing_time=2.5,
            quality_score=85.0,
            cost=0.05
        )
    
    async def predict_adoption_probability(
        self,
        application_data: Dict,
        subsidy_program: Dict
    ) -> AIResponse:
        # ãƒ¢ãƒƒã‚¯æ¡æŠå¯èƒ½æ€§äºˆæ¸¬
        await asyncio.sleep(0.1)
        
        prediction_result = {
            "adoption_probability": 0.75,
            "confidence_score": 0.85,
            "score_breakdown": {
                "innovation_score": 80,
                "feasibility_score": 75,
                "market_potential_score": 85,
                "budget_adequacy_score": 70
            },
            "key_strengths": ["æŠ€è¡“é©æ–°æ€§", "å¸‚å ´æ€§", "å®Ÿç¾å¯èƒ½æ€§"],
            "key_weaknesses": ["äºˆç®—è¨ˆç”»ã®è©³ç´°åŒ–ãŒå¿…è¦"],
            "improvement_suggestions": [
                "å…·ä½“çš„ãªæ•°å€¤ç›®æ¨™ã‚’è¿½åŠ ",
                "ç«¶åˆåˆ†æã‚’å¼·åŒ–",
                "ãƒªã‚¹ã‚¯å¯¾ç­–ã‚’æ˜è¨˜"
            ]
        }
        
        return AIResponse(
            request_id=f"ap_{int(datetime.now().timestamp())}",
            success=True,
            content=json.dumps(prediction_result, ensure_ascii=False),
            provider="anthropic",
            processing_time=1.8,
            quality_score=88.0,
            confidence_score=0.85,
            cost=0.03
        )
    
    async def analyze_document(
        self,
        document_text: str,
        analysis_type: str = "comprehensive"
    ) -> AIResponse:
        # ãƒ¢ãƒƒã‚¯æ–‡æ›¸è§£æ
        await asyncio.sleep(0.1)
        
        analysis_result = {
            "summary": document_text[:200] + "..." if len(document_text) > 200 else document_text,
            "key_points": ["ãƒã‚¤ãƒ³ãƒˆ1", "ãƒã‚¤ãƒ³ãƒˆ2", "ãƒã‚¤ãƒ³ãƒˆ3"],
            "sentiment": "positive",
            "quality_score": 78,
            "readability_score": 82,
            "entities": {
                "organizations": ["ãƒ†ã‚¹ãƒˆä¼šç¤¾"],
                "monetary_values": ["500ä¸‡å††"],
                "dates": ["12ãƒ¶æœˆ"]
            }
        }
        
        return AIResponse(
            request_id=f"da_{int(datetime.now().timestamp())}",
            success=True,
            content=json.dumps(analysis_result, ensure_ascii=False),
            provider="openai",
            processing_time=1.2,
            quality_score=78.0,
            cost=0.02
        )

# ãƒ¢ãƒƒã‚¯ç‰ˆ AdoptionPredictor
@dataclass
class ApplicationFeatures:
    text_length: int
    keyword_density: float
    innovation_score: float
    market_potential: float
    feasibility_score: float
    budget_reasonableness: float
    company_track_record: float
    industry_alignment: float
    technology_readiness: float
    team_capability: float
    risk_assessment: float
    competitive_advantage: float

@dataclass
class PredictionResult:
    adoption_probability: float
    confidence_score: float
    score_breakdown: Dict[str, float]
    key_factors: List[str]
    improvement_suggestions: List[str]
    risk_factors: List[str]
    benchmark_comparison: Dict[str, float]
    prediction_explanation: List[str]

class MockAdoptionPredictor:
    def __init__(self):
        self.classifier = None
    
    def predict_adoption_probability(
        self,
        application_data: Dict,
        subsidy_program: Dict,
        company_profile: Dict
    ) -> PredictionResult:
        # ãƒ¢ãƒƒã‚¯äºˆæ¸¬
        features = self._extract_comprehensive_features(
            application_data, subsidy_program, company_profile
        )
        
        return PredictionResult(
            adoption_probability=0.78,
            confidence_score=0.82,
            score_breakdown={
                "innovation_score": 82.0,
                "market_potential_score": 78.0,
                "feasibility_score": 85.0,
                "budget_adequacy_score": 75.0,
                "company_strength_score": 80.0
            },
            key_factors=["é©æ–°æ€§", "å¸‚å ´æ€§", "å®Ÿç¾å¯èƒ½æ€§"],
            improvement_suggestions=["æŠ€è¡“çš„è©³ç´°ã®è¿½åŠ ", "äºˆç®—è¨ˆç”»ã®ç²¾ç·»åŒ–"],
            risk_factors=["ç«¶åˆã®å­˜åœ¨", "æŠ€è¡“çš„èª²é¡Œ"],
            benchmark_comparison={"industry_average": 110.0},
            prediction_explanation=["é«˜ã„é©æ–°æ€§ãŒè©•ä¾¡", "å¸‚å ´æ€§ã‚‚è‰¯å¥½"]
        )
    
    def _extract_comprehensive_features(
        self,
        application_data: Dict,
        subsidy_program: Dict,
        company_profile: Dict
    ) -> ApplicationFeatures:
        return ApplicationFeatures(
            text_length=len(str(application_data.get('content', ''))),
            keyword_density=0.7,
            innovation_score=0.8,
            market_potential=0.75,
            feasibility_score=0.85,
            budget_reasonableness=0.9,
            company_track_record=0.7,
            industry_alignment=0.95,
            technology_readiness=0.8,
            team_capability=0.75,
            risk_assessment=0.8,
            competitive_advantage=0.7
        )

# ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹
class TestMockAIServices:
    """ãƒ¢ãƒƒã‚¯ç‰ˆAIã‚µãƒ¼ãƒ“ã‚¹ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def ai_service(self):
        return MockEnhancedAIService()

    @pytest.fixture
    def sample_company_data(self):
        return {
            'name': 'ãƒ†ã‚¹ãƒˆæ ªå¼ä¼šç¤¾',
            'industry': 'ITãƒ»ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢',
            'employee_count': 50,
            'description': 'Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³é–‹ç™ºã¨AIã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³æä¾›',
            'founded_year': 2020,
            'revenue': 500000000
        }

    @pytest.mark.asyncio
    async def test_business_plan_generation(self, ai_service, sample_company_data):
        """äº‹æ¥­è¨ˆç”»æ›¸ç”Ÿæˆãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        result = await ai_service.generate_business_plan(
            company_data=sample_company_data,
            subsidy_type='ITå°å…¥è£œåŠ©é‡‘',
            custom_requirements=['DXæ¨é€²', 'ã‚¯ãƒ©ã‚¦ãƒ‰å°å…¥'],
            provider=AIProvider.HYBRID
        )
        
        assert isinstance(result, AIResponse)
        assert result.success is True
        assert result.content is not None
        assert len(result.content) > 100
        assert result.quality_score >= 0
        assert result.processing_time > 0
        
        # JSONãƒ‘ãƒ¼ã‚¹å¯èƒ½ã‹ãƒã‚§ãƒƒã‚¯
        content_data = json.loads(result.content)
        assert isinstance(content_data, dict)
        assert 'companyOverview' in content_data
        
        print(f"âœ… äº‹æ¥­è¨ˆç”»æ›¸ç”Ÿæˆãƒ†ã‚¹ãƒˆå®Œäº†: æˆåŠŸ")

    @pytest.mark.asyncio
    async def test_adoption_prediction(self, ai_service, sample_company_data):
        """æ¡æŠå¯èƒ½æ€§äºˆæ¸¬ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        application_data = {
            'content': 'AIæŠ€è¡“ã‚’æ´»ç”¨ã—ãŸæ¥­å‹™åŠ¹ç‡åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™ºãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ',
            'budget': {'total': 3000000},
            'timeline': '6ãƒ¶æœˆ'
        }
        
        subsidy_program = {
            'type': 'ITå°å…¥è£œåŠ©é‡‘',
            'max_amount': 5000000,
            'target_industries': ['IT', 'è£½é€ æ¥­']
        }
        
        result = await ai_service.predict_adoption_probability(
            application_data=application_data,
            subsidy_program=subsidy_program
        )
        
        assert isinstance(result, AIResponse)
        assert result.success is True
        assert result.content is not None
        
        prediction_data = json.loads(result.content)
        assert 'adoption_probability' in prediction_data
        assert 'confidence_score' in prediction_data
        assert 0 <= prediction_data['adoption_probability'] <= 1
        
        print(f"âœ… æ¡æŠå¯èƒ½æ€§äºˆæ¸¬ãƒ†ã‚¹ãƒˆå®Œäº†: æˆåŠŸ")

    @pytest.mark.asyncio
    async def test_document_analysis(self, ai_service):
        """æ–‡æ›¸è§£æãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        test_document = """
        å¼Šç¤¾ã¯ AI æŠ€è¡“ã‚’æ´»ç”¨ã—ãŸé©æ–°çš„ãªã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é–‹ç™ºã—ã¦ãŠã‚Šã€
        æ¥­å‹™åŠ¹ç‡åŒ–ã¨é¡§å®¢æº€è¶³åº¦å‘ä¸Šã‚’ç›®æŒ‡ã—ã¦ã„ã¾ã™ã€‚
        ã“ã®åº¦ã€ITå°å…¥è£œåŠ©é‡‘ã‚’æ´»ç”¨ã—ã¦ã€ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ™ãƒ¼ã‚¹ã®çµ±åˆç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€
        å¹´é–“ 30% ã®æ¥­å‹™åŠ¹ç‡å‘ä¸Šã¨ 20% ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
        """
        
        result = await ai_service.analyze_document(
            document_text=test_document,
            analysis_type="comprehensive"
        )
        
        assert isinstance(result, AIResponse)
        assert result.success is True
        assert result.content is not None
        assert len(result.content) > 50
        
        analysis_data = json.loads(result.content)
        assert 'summary' in analysis_data
        assert 'quality_score' in analysis_data
        
        print(f"âœ… æ–‡æ›¸è§£æãƒ†ã‚¹ãƒˆå®Œäº†: æˆåŠŸ")


class TestMockAdoptionPredictor:
    """ãƒ¢ãƒƒã‚¯ç‰ˆæ¡æŠå¯èƒ½æ€§äºˆæ¸¬å™¨ãƒ†ã‚¹ãƒˆ"""
    
    @pytest.fixture
    def predictor(self):
        return MockAdoptionPredictor()

    @pytest.fixture
    def sample_application(self):
        return {
            'content': 'AIæŠ€è¡“ã‚’æ´»ç”¨ã—ãŸè£½é€ æ¥­å‘ã‘å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®é–‹ç™º',
            'budget': {'total': 2000000},
            'timeline': '8ãƒ¶æœˆ'
        }

    @pytest.fixture
    def sample_subsidy_program(self):
        return {
            'type': 'ã‚‚ã®ã¥ãã‚Šè£œåŠ©é‡‘',
            'max_amount': 10000000,
            'target_industries': ['è£½é€ æ¥­', 'IT']
        }

    @pytest.fixture
    def sample_company_profile(self):
        return {
            'name': 'ãƒ†ãƒƒã‚¯è£½é€ æ ªå¼ä¼šç¤¾',
            'industry': 'è£½é€ æ¥­',
            'employee_count': 100,
            'founded_year': 2015,
            'revenue': 1000000000
        }

    def test_feature_extraction(self, predictor, sample_application, sample_subsidy_program, sample_company_profile):
        """ç‰¹å¾´é‡æŠ½å‡ºãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        features = predictor._extract_comprehensive_features(
            sample_application,
            sample_subsidy_program,
            sample_company_profile
        )
        
        assert isinstance(features, ApplicationFeatures)
        assert features.text_length > 0
        assert 0 <= features.keyword_density <= 1
        assert 0 <= features.innovation_score <= 1
        assert 0 <= features.market_potential <= 1
        assert 0 <= features.feasibility_score <= 1
        
        print("âœ… ç‰¹å¾´é‡æŠ½å‡ºãƒ†ã‚¹ãƒˆå®Œäº†: æˆåŠŸ")

    def test_prediction(self, predictor, sample_application, sample_subsidy_program, sample_company_profile):
        """äºˆæ¸¬ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        result = predictor.predict_adoption_probability(
            sample_application,
            sample_subsidy_program,
            sample_company_profile
        )
        
        assert isinstance(result, PredictionResult)
        assert 0 <= result.adoption_probability <= 1
        assert 0 <= result.confidence_score <= 1
        assert isinstance(result.score_breakdown, dict)
        assert isinstance(result.key_factors, list)
        assert isinstance(result.improvement_suggestions, list)
        
        print(f"âœ… äºˆæ¸¬ãƒ†ã‚¹ãƒˆå®Œäº†: æ¡æŠç¢ºç‡ {result.adoption_probability:.3f}")


class TestIntegrationMock:
    """çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
    
    @pytest.mark.asyncio
    async def test_full_workflow_mock(self):
        """å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        print("\nğŸš€ å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆãƒ¢ãƒƒã‚¯ç‰ˆï¼‰")
        
        # 1. AI ã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–
        ai_service = MockEnhancedAIService()
        
        # 2. ä¼æ¥­ãƒ‡ãƒ¼ã‚¿æº–å‚™
        company_data = {
            'name': 'çµ±åˆãƒ†ã‚¹ãƒˆæ ªå¼ä¼šç¤¾',
            'industry': 'ITãƒ»ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢',
            'employee_count': 75,
            'description': 'AIæŠ€è¡“ã¨ã‚¯ãƒ©ã‚¦ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã®é–‹ç™º'
        }
        
        # 3. äº‹æ¥­è¨ˆç”»æ›¸ç”Ÿæˆ
        business_plan_result = await ai_service.generate_business_plan(
            company_data=company_data,
            subsidy_type='ITå°å…¥è£œåŠ©é‡‘',
            provider=AIProvider.HYBRID
        )
        
        assert business_plan_result.success is True
        print(f"  âœ… äº‹æ¥­è¨ˆç”»æ›¸ç”Ÿæˆ: {business_plan_result.success}")
        
        # 4. ç”Ÿæˆã•ã‚ŒãŸå†…å®¹ã§æ¡æŠå¯èƒ½æ€§äºˆæ¸¬
        application_data = {
            'content': business_plan_result.content[:500],
            'budget': {'total': 3000000}
        }
        
        subsidy_program = {
            'type': 'ITå°å…¥è£œåŠ©é‡‘',
            'max_amount': 5000000
        }
        
        prediction_result = await ai_service.predict_adoption_probability(
            application_data=application_data,
            subsidy_program=subsidy_program
        )
        
        assert prediction_result.success is True
        print(f"  âœ… æ¡æŠå¯èƒ½æ€§äºˆæ¸¬: {prediction_result.success}")
        
        # 5. æ–‡æ›¸è§£æ
        test_document = """
        ITå°å…¥è£œåŠ©é‡‘ã‚’æ´»ç”¨ã—ãŸã‚¯ãƒ©ã‚¦ãƒ‰ã‚·ã‚¹ãƒ†ãƒ å°å…¥ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã€‚
        æ¥­å‹™åŠ¹ç‡åŒ–ã«ã‚ˆã‚Šå¹´é–“20%ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’ç›®æŒ‡ã—ã¾ã™ã€‚
        """
        
        analysis_result = await ai_service.analyze_document(
            document_text=test_document,
            analysis_type="basic"
        )
        
        assert analysis_result.success is True
        print(f"  âœ… æ–‡æ›¸è§£æ: {analysis_result.success}")
        
        print("ğŸ‰ å®Œå…¨ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆãƒ¢ãƒƒã‚¯ç‰ˆï¼‰")

    def test_error_handling_mock(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        print("\nğŸ›¡ï¸ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆé–‹å§‹ï¼ˆãƒ¢ãƒƒã‚¯ç‰ˆï¼‰")
        
        ai_service = MockEnhancedAIService()
        
        # ç©ºã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆ
        empty_result = asyncio.run(ai_service.generate_business_plan(
            company_data={},
            subsidy_type='',
            provider=AIProvider.OPENAI
        ))
        
        # ãƒ¢ãƒƒã‚¯ã¯å¸¸ã«æˆåŠŸã™ã‚‹ã®ã§ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚’ãƒã‚§ãƒƒã‚¯
        assert isinstance(empty_result, AIResponse)
        assert hasattr(empty_result, 'success')
        assert hasattr(empty_result, 'content')
        print(f"  âœ… ç©ºãƒ‡ãƒ¼ã‚¿ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ æ­£å¸¸")
        
        print("ğŸ‰ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆãƒ¢ãƒƒã‚¯ç‰ˆï¼‰")


# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
def run_mock_tests():
    """ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ"""
    print("=" * 60)
    print("ğŸ§ª AI ã‚µãƒ¼ãƒ“ã‚¹çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œé–‹å§‹ï¼ˆãƒ¢ãƒƒã‚¯ç‰ˆï¼‰")
    print("=" * 60)
    
    # pytestå®Ÿè¡Œ
    result = pytest.main([
        __file__,
        "-v",
        "--tb=short"
    ])
    
    return result


if __name__ == "__main__":
    # ç›´æ¥å®Ÿè¡Œæ™‚ã®ã‚¯ã‚¤ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
    async def quick_mock_test():
        """ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        print("ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
        
        try:
            # åŸºæœ¬çš„ãªåˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
            ai_service = MockEnhancedAIService()
            print("âœ… ãƒ¢ãƒƒã‚¯AIã‚µãƒ¼ãƒ“ã‚¹åˆæœŸåŒ–æˆåŠŸ")
            
            predictor = MockAdoptionPredictor()
            print("âœ… ãƒ¢ãƒƒã‚¯æ¡æŠäºˆæ¸¬å™¨åˆæœŸåŒ–æˆåŠŸ")
            
            # ç°¡å˜ãªå‹•ä½œãƒ†ã‚¹ãƒˆ
            company_data = {
                'name': 'ãƒ†ã‚¹ãƒˆä¼šç¤¾',
                'industry': 'IT',
                'employee_count': 50,
                'description': 'ãƒ†ã‚¹ãƒˆç”¨ä¼šç¤¾'
            }
            
            result = await ai_service.generate_business_plan(
                company_data=company_data,
                subsidy_type='ãƒ†ã‚¹ãƒˆè£œåŠ©é‡‘'
            )
            
            assert result.success is True
            print("âœ… ãƒ¢ãƒƒã‚¯äº‹æ¥­è¨ˆç”»æ›¸ç”Ÿæˆãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
            prediction = predictor.predict_adoption_probability(
                {'content': 'ãƒ†ã‚¹ãƒˆç”³è«‹'}, 
                {'type': 'ãƒ†ã‚¹ãƒˆè£œåŠ©é‡‘'}, 
                company_data
            )
            
            assert prediction.adoption_probability > 0
            print("âœ… ãƒ¢ãƒƒã‚¯æ¡æŠäºˆæ¸¬ãƒ†ã‚¹ãƒˆæˆåŠŸ")
            
            print("\nğŸ‰ ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
            
        except Exception as e:
            print(f"âŒ ã‚¯ã‚¤ãƒƒã‚¯ãƒ¢ãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            import traceback
            traceback.print_exc()
    
    asyncio.run(quick_mock_test())
    
    # ãƒ•ãƒ«ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    run_mock_tests()