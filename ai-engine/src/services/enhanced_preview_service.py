"""
Enhanced PDF ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰èª²é‡‘ãƒ¢ãƒ‡ãƒ«å¯¾å¿œã®é«˜åº¦ãªãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½
"""

from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
import asyncio
import logging
import json
import hashlib
from pathlib import Path

logger = logging.getLogger(__name__)


class QualityLevel(Enum):
    """å“è³ªãƒ¬ãƒ™ãƒ«"""
    EXCELLENT = "excellent"     # 85ç‚¹ä»¥ä¸Š
    GOOD = "good"              # 70-84ç‚¹
    FAIR = "fair"              # 55-69ç‚¹
    NEEDS_IMPROVEMENT = "needs_improvement"  # 55ç‚¹æœªæº€


@dataclass
class ValueProposition:
    """ä¾¡å€¤è¨´æ±‚è¦ç´ """
    price_justification: str
    quality_highlights: List[str]
    success_indicators: Dict[str, Any]
    user_benefits: List[str]
    risk_mitigation: List[str]


@dataclass
class SmartPreview:
    """ã‚¹ãƒãƒ¼ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼çµæœ"""
    preview_id: str
    preview_content: Dict[str, Any]
    quality_level: QualityLevel
    overall_score: float
    category_scores: Dict[str, float]
    value_proposition: ValueProposition
    improvement_suggestions: List[Dict[str, Any]]
    success_probability: float
    benchmark_comparison: Dict[str, Any]
    personalized_message: str
    purchase_urgency: Optional[str] = None


class EnhancedPreviewService:
    """Enhanced ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, output_dir: str = "output/enhanced_previews"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.preview_cache = {}
        
        # æ¡æŠå®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã¯DBã‹ã‚‰å–å¾—ï¼‰
        self.success_data = {
            "total_applications": 1247,
            "total_adopted": 896,
            "average_success_rate": 0.72,
            "by_quality_score": {
                "85+": 0.89,
                "70-84": 0.76,
                "55-69": 0.58,
                "55-": 0.31
            }
        }
    
    async def generate_smart_preview(
        self,
        application_data: Dict[str, Any],
        user_context: Dict[str, Any] = None
    ) -> SmartPreview:
        """
        ã‚¹ãƒãƒ¼ãƒˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”Ÿæˆ
        ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆãªä¾¡å€¤è¨´æ±‚ã‚’å«ã‚€
        """
        try:
            if user_context is None:
                user_context = {}
            
            preview_id = self._generate_preview_id(application_data)
            
            # 1. åŒ…æ‹¬çš„å“è³ªè©•ä¾¡
            quality_analysis = await self._comprehensive_quality_analysis(
                application_data
            )
            
            # 2. ä¾¡å€¤è¨´æ±‚ã®ç”Ÿæˆ
            value_proposition = await self._generate_value_proposition(
                quality_analysis, user_context
            )
            
            # 3. ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            personalized_message = self._create_personalized_message(
                quality_analysis, user_context
            )
            
            # 4. æ”¹å–„ææ¡ˆï¼ˆåŠ¹æœé †ï¼‰
            improvements = await self._generate_prioritized_improvements(
                application_data, quality_analysis
            )
            
            # 5. ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒ
            benchmark = self._generate_benchmark_comparison(quality_analysis)
            
            # 6. ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ
            preview_content = await self._create_enhanced_preview_content(
                application_data, quality_analysis
            )
            
            return SmartPreview(
                preview_id=preview_id,
                preview_content=preview_content,
                quality_level=self._determine_quality_level(quality_analysis["overall_score"]),
                overall_score=quality_analysis["overall_score"],
                category_scores=quality_analysis["category_scores"],
                value_proposition=value_proposition,
                improvement_suggestions=improvements,
                success_probability=quality_analysis["success_probability"],
                benchmark_comparison=benchmark,
                personalized_message=personalized_message,
                purchase_urgency=self._determine_purchase_urgency(quality_analysis)
            )
            
        except Exception as e:
            logger.error(f"Enhanced preview generation error: {str(e)}")
            raise
    
    async def _comprehensive_quality_analysis(
        self,
        application_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„å“è³ªåˆ†æ"""
        
        # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ã‚¹ã‚³ã‚¢è¨ˆç®—
        category_scores = {
            "completeness": await self._evaluate_completeness(application_data),
            "coherence": await self._evaluate_coherence(application_data),
            "persuasiveness": await self._evaluate_persuasiveness(application_data),
            "technical_accuracy": await self._evaluate_technical_accuracy(application_data),
            "innovation": await self._evaluate_innovation(application_data),
            "feasibility": await self._evaluate_feasibility(application_data)
        }
        
        # é‡ã¿ä»˜ãç·åˆã‚¹ã‚³ã‚¢
        weights = {
            "completeness": 0.20,
            "coherence": 0.18,
            "persuasiveness": 0.18,
            "technical_accuracy": 0.15,
            "innovation": 0.15,
            "feasibility": 0.14
        }
        
        overall_score = sum(
            category_scores[category] * weight
            for category, weight in weights.items()
        )
        
        # æˆåŠŸç¢ºç‡äºˆæ¸¬
        success_probability = self._predict_success_rate(overall_score, category_scores)
        
        return {
            "overall_score": round(overall_score, 1),
            "category_scores": {k: round(v, 1) for k, v in category_scores.items()},
            "success_probability": round(success_probability, 3),
            "strengths": self._identify_strengths(category_scores),
            "weaknesses": self._identify_weaknesses(category_scores)
        }
    
    async def _generate_value_proposition(
        self,
        quality_analysis: Dict[str, Any],
        user_context: Dict[str, Any]
    ) -> ValueProposition:
        """ä¾¡å€¤è¨´æ±‚ã®ç”Ÿæˆ"""
        
        score = quality_analysis["overall_score"]
        success_rate = quality_analysis["success_probability"]
        
        # ãªãœ3,980å††ã®ä¾¡å€¤ãŒã‚ã‚‹ã‹ã®èª¬æ˜
        if score >= 85:
            price_justification = (
                f"å“è³ªã‚¹ã‚³ã‚¢{score}ç‚¹ã®ç”³è«‹æ›¸ã¯ã€æ¡æŠç‡{success_rate*100:.0f}%ã¨"
                "éå¸¸ã«é«˜ã„æˆåŠŸç¢ºç‡ã‚’æŒã¡ã¾ã™ã€‚å°‚é–€ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã«ä¾é ¼ã™ã‚‹ã¨"
                "30ä¸‡å††ä»¥ä¸Šã‹ã‹ã‚‹å“è³ªã‚’ã€ã‚ãšã‹3,980å††ã§å®Ÿç¾ã—ã¾ã™ã€‚"
            )
        elif score >= 70:
            price_justification = (
                f"å“è³ªã‚¹ã‚³ã‚¢{score}ç‚¹ã¯å¹³å‡ã‚’å¤§ããä¸Šå›ã‚‹å“è³ªã§ã™ã€‚"
                f"æ¡æŠç‡{success_rate*100:.0f}%ã§ã€æŠ•è³‡å¯¾åŠ¹æœã¯æŠœç¾¤ã§ã™ã€‚"
                "ç”³è«‹æº–å‚™ã«ã‹ã‹ã‚‹æ™‚é–“çŸ­ç¸®åŠ¹æœã‚‚å«ã‚ã‚‹ã¨ã€åœ§å€’çš„ã«ãŠå¾—ã§ã™ã€‚"
            )
        else:
            price_justification = (
                "åŸºæœ¬çš„ãªç”³è«‹æ›¸ã®ä½œæˆã¨ã€æ”¹å–„ææ¡ˆã«ã‚ˆã‚Šå“è³ªå‘ä¸ŠãŒå¯èƒ½ã§ã™ã€‚"
                "è‡ªåŠ›ã§ä½œæˆã™ã‚‹å ´åˆã®æ™‚é–“ã‚³ã‚¹ãƒˆï¼ˆ40æ™‚é–“ä»¥ä¸Šï¼‰ã‚’è€ƒãˆã‚‹ã¨ã€"
                "åŠ¹ç‡çš„ãªé¸æŠè‚¢ã§ã™ã€‚"
            )
        
        # å“è³ªãƒã‚¤ãƒ©ã‚¤ãƒˆ
        quality_highlights = []
        if score >= 80:
            quality_highlights.append("ğŸ† ä¸Šä½20%ã®é«˜å“è³ªç”³è«‹æ›¸")
        if quality_analysis["category_scores"]["persuasiveness"] >= 80:
            quality_highlights.append("ğŸ’ª é«˜ã„èª¬å¾—åŠ›ã‚’æŒã¤æ§‹æˆ")
        if quality_analysis["category_scores"]["innovation"] >= 75:
            quality_highlights.append("ğŸ’¡ é©æ–°æ€§ãŒè©•ä¾¡ã•ã‚Œã‚‹å†…å®¹")
        if quality_analysis["category_scores"]["feasibility"] >= 80:
            quality_highlights.append("âœ… å®Ÿç¾å¯èƒ½æ€§ã®é«˜ã„è¨ˆç”»")
        
        # æˆåŠŸæŒ‡æ¨™
        success_indicators = {
            "predicted_success_rate": f"{success_rate*100:.0f}%",
            "quality_ranking": self._get_quality_ranking(score),
            "benchmark_comparison": f"å¹³å‡ã‚ˆã‚Š{score-65:.0f}ç‚¹é«˜ã„",
            "expert_validation": "å°‚é–€å®¶ãƒ¬ãƒ“ãƒ¥ãƒ¼æ¸ˆã¿å“è³ª"
        }
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒªãƒƒãƒˆ
        user_benefits = [
            "ğŸ“„ å³åº§ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ãªå®Œæˆç‰ˆPDF",
            "ğŸ”„ 24æ™‚é–“ä»¥å†…ãªã‚‰3å›ã¾ã§å†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            "ğŸ“ å°‚ä»»ã‚µãƒãƒ¼ãƒˆã«ã‚ˆã‚‹ç”³è«‹ç›¸è«‡",
            "ğŸ“Š è©³ç´°ãªå“è³ªåˆ†æãƒ¬ãƒãƒ¼ãƒˆä»˜ã",
            "ğŸ’° ã‚³ãƒ³ã‚µãƒ«è²»ç”¨ã®90%ä»¥ä¸Šç¯€ç´„"
        ]
        
        # ãƒªã‚¹ã‚¯è»½æ¸›
        risk_mitigation = [
            "24æ™‚é–“ä»¥å†…ã®ç„¡æ¡ä»¶è¿”é‡‘ä¿è¨¼",
            "SSLæš—å·åŒ–ã«ã‚ˆã‚‹å®‰å…¨ãªæ±ºæ¸ˆ",
            "å€‹äººæƒ…å ±ã®æœ€å°é™åé›†",
            "å°‚é–€å®¶ã«ã‚ˆã‚‹ã‚µãƒãƒ¼ãƒˆä½“åˆ¶"
        ]
        
        return ValueProposition(
            price_justification=price_justification,
            quality_highlights=quality_highlights,
            success_indicators=success_indicators,
            user_benefits=user_benefits,
            risk_mitigation=risk_mitigation
        )
    
    def _create_personalized_message(
        self,
        quality_analysis: Dict[str, Any],
        user_context: Dict[str, Any]
    ) -> str:
        """ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
        
        score = quality_analysis["overall_score"]
        success_rate = quality_analysis["success_probability"]
        
        # éå»ã®åˆ©ç”¨å±¥æ­´ã‚’è€ƒæ…®
        is_returning = user_context.get("is_returning_user", False)
        previous_quality = user_context.get("previous_quality_score", 0)
        
        if is_returning and previous_quality > 0:
            if score > previous_quality:
                return (
                    f"ç´ æ™´ã‚‰ã—ã„æ”¹å–„ã§ã™ï¼å‰å›ã‚ˆã‚Š{score-previous_quality:.1f}ç‚¹å‘ä¸Šã—ã€"
                    f"æ¡æŠç‡ã‚‚{success_rate*100:.0f}%ã¾ã§ä¸ŠãŒã‚Šã¾ã—ãŸã€‚"
                    "ã“ã®å“è³ªãªã‚‰è‡ªä¿¡ã‚’æŒã£ã¦ç”³è«‹ã§ãã¾ã™ã€‚"
                )
            else:
                return (
                    f"ä»Šå›ã‚‚å®‰å®šã—ãŸå“è³ªï¼ˆ{score}ç‚¹ï¼‰ã‚’å®Ÿç¾ã•ã‚Œã¾ã—ãŸã€‚"
                    "ç¶™ç¶šçš„ã«ã”åˆ©ç”¨ã„ãŸã ãã€ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚"
                )
        
        # åˆå›ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘
        if score >= 85:
            return (
                f"ğŸ‰ ç´ æ™´ã‚‰ã—ã„ï¼{score}ç‚¹ã®é«˜å“è³ªç”³è«‹æ›¸ãŒå®Œæˆã—ã¾ã—ãŸã€‚"
                f"æ¡æŠç‡{success_rate*100:.0f}%ã¨ã„ã†å„ªç§€ãªçµæœãŒæœŸå¾…ã§ãã¾ã™ã€‚"
                "ãœã²ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”³è«‹ã«ãŠé€²ã¿ãã ã•ã„ï¼"
            )
        elif score >= 70:
            return (
                f"è‰¯ã„ç”³è«‹æ›¸ãŒã§ãã¾ã—ãŸï¼ˆ{score}ç‚¹ï¼‰ã€‚"
                f"æ¡æŠç‡{success_rate*100:.0f}%ã§ã€ååˆ†ã«ç«¶äº‰åŠ›ãŒã‚ã‚Šã¾ã™ã€‚"
                "æ”¹å–„ææ¡ˆã‚‚å‚è€ƒã«ã€ã•ã‚‰ã«å“è³ªã‚’é«˜ã‚ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚"
            )
        else:
            return (
                "åŸºæœ¬çš„ãªç”³è«‹æ›¸ãŒå®Œæˆã—ã¾ã—ãŸã€‚æ”¹å–„ææ¡ˆã‚’å‚è€ƒã«ã€"
                "ã‚ˆã‚Šé«˜ã„æ¡æŠç‡ã‚’ç›®æŒ‡ã™ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
            )
    
    async def _generate_prioritized_improvements(
        self,
        application_data: Dict[str, Any],
        quality_analysis: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """å„ªå…ˆåº¦ä»˜ãæ”¹å–„ææ¡ˆ"""
        
        improvements = []
        category_scores = quality_analysis["category_scores"]
        
        # å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®æ”¹å–„ææ¡ˆ
        if category_scores["completeness"] < 80:
            improvements.append({
                "priority": "high",
                "category": "completeness",
                "title": "å¿…é ˆé …ç›®ã®å……å®Ÿ",
                "description": "å¸‚å ´åˆ†æã‚„ç«¶åˆæ¯”è¼ƒã®è©³ç´°ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ã§ã€èª¬å¾—åŠ›ãŒå‘ä¸Šã—ã¾ã™ã€‚",
                "impact": "+8ã€œ12ç‚¹",
                "effort": "ä¸­",
                "specific_actions": [
                    "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¸‚å ´ã®è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ",
                    "ç«¶åˆä»–ç¤¾ã¨ã®å·®åˆ¥åŒ–è¦å› ã‚’æ˜è¨˜",
                    "å£²ä¸Šäºˆæ¸¬ã®æ ¹æ‹ ã‚’è©³ç´°åŒ–"
                ]
            })
        
        if category_scores["persuasiveness"] < 75:
            improvements.append({
                "priority": "high",
                "category": "persuasiveness",
                "title": "èª¬å¾—åŠ›ã®å¼·åŒ–",
                "description": "å…·ä½“çš„ãªæ•°å€¤ã¨ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ã§ã€å¯©æŸ»å“¡ã®å¿ƒã‚’æ´ã‚€å†…å®¹ã«ã€‚",
                "impact": "+6ã€œ10ç‚¹",
                "effort": "ä¸­",
                "specific_actions": [
                    "æˆåŠŸäº‹ä¾‹ã®å…·ä½“çš„ãªæ•°å€¤ã‚’è¿½åŠ ",
                    "å®Ÿç¾ãƒ—ãƒ­ã‚»ã‚¹ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’è©³ç´°åŒ–",
                    "æœŸå¾…åŠ¹æœã®å®šé‡çš„ãªèª¬æ˜ã‚’å¼·åŒ–"
                ]
            })
        
        if category_scores["innovation"] < 70:
            improvements.append({
                "priority": "medium",
                "category": "innovation",
                "title": "é©æ–°æ€§ã®ã‚¢ãƒ”ãƒ¼ãƒ«",
                "description": "ç‹¬è‡ªæ€§ã¨æ–°è¦æ€§ã‚’ã‚ˆã‚Šå¼·èª¿ã—ã¦ã€ä»–ç¤¾ã¨ã®å·®åˆ¥åŒ–ã‚’æ˜ç¢ºã«ã€‚",
                "impact": "+5ã€œ8ç‚¹",
                "effort": "é«˜",
                "specific_actions": [
                    "æŠ€è¡“çš„ãªç‹¬è‡ªæ€§ã‚’å…·ä½“çš„ã«èª¬æ˜",
                    "å¾“æ¥æ‰‹æ³•ã¨ã®æ¯”è¼ƒè¡¨ã‚’ä½œæˆ",
                    "ç‰¹è¨±ã‚„çŸ¥çš„è²¡ç”£ã®æ´»ç”¨ã‚’è¨˜è¼‰"
                ]
            })
        
        # åŠ¹æœã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
        improvements.sort(key=lambda x: {
            "high": 3, "medium": 2, "low": 1
        }[x["priority"]], reverse=True)
        
        return improvements[:3]  # ä¸Šä½3ã¤ã«çµã‚‹
    
    def _generate_benchmark_comparison(
        self,
        quality_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒ"""
        
        score = quality_analysis["overall_score"]
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«è¨ˆç®—
        if score >= 85:
            percentile = 90
        elif score >= 80:
            percentile = 80
        elif score >= 75:
            percentile = 70
        elif score >= 70:
            percentile = 60
        elif score >= 65:
            percentile = 50
        else:
            percentile = 30
        
        return {
            "percentile": percentile,
            "comparison_text": f"ä¸Šä½{100-percentile}%ã®å“è³ª",
            "average_comparison": f"å¹³å‡ã‚ˆã‚Š{score-65:.1f}ç‚¹é«˜ã„",
            "success_rate_vs_average": f"å¹³å‡æ¡æŠç‡ã‚ˆã‚Š{((quality_analysis['success_probability'] - 0.45) * 100):.0f}%é«˜ã„"
        }
    
    async def _create_enhanced_preview_content(
        self,
        application_data: Dict[str, Any],
        quality_analysis: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Enhanced ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ç”Ÿæˆ"""
        
        # åŸºæœ¬æƒ…å ±ã¯å®Œå…¨è¡¨ç¤º
        preview_content = {
            "basic_info": application_data.get("company_info", {}),
            "project_title": application_data.get("project_info", {}).get("project_title", ""),
        }
        
        # è©³ç´°ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯æˆ¦ç•¥çš„ã«ä¸€éƒ¨è¡¨ç¤º
        business_plan = application_data.get("business_plan", "")
        if len(business_plan) > 200:
            preview_content["business_plan"] = (
                business_plan[:200] + 
                "\n\n[...ç¶šãã®è©³ç´°ãªäº‹æ¥­è¨ˆç”»ã¯å®Œå…¨ç‰ˆã§ã”ç¢ºèªã„ãŸã ã‘ã¾ã™...]"
            )
        else:
            preview_content["business_plan"] = business_plan
        
        # è²¡å‹™è¨ˆç”»ã¯éƒ¨åˆ†çš„ã«ã¼ã‹ã—
        financial_data = application_data.get("financial_plan", {})
        preview_content["financial_plan"] = {
            "æ¦‚è¦": "è©³ç´°ãªåæ”¯è¨ˆç”»ã¨è³‡é‡‘èª¿é”æˆ¦ç•¥",
            "å£²ä¸Šäºˆæ¸¬": "â–ˆâ–ˆâ–ˆå¹´é–“ã§â–ˆâ–ˆï¼…æˆé•·",
            "æŠ•è³‡è¨ˆç”»": "è¨­å‚™æŠ•è³‡â–ˆâ–ˆä¸‡å††ã€é‹è»¢è³‡é‡‘â–ˆâ–ˆä¸‡å††",
            "å®Œå…¨ç‰ˆ": "å…·ä½“çš„ãªæ•°å€¤ã¨æ ¹æ‹ ã¯å®Œå…¨ç‰ˆã«è¨˜è¼‰"
        }
        
        # å“è³ªè©•ä¾¡çµæœã‚’è¿½åŠ 
        preview_content["quality_evaluation"] = {
            "overall_score": quality_analysis["overall_score"],
            "category_scores": quality_analysis["category_scores"],
            "strengths": quality_analysis["strengths"],
            "improvement_areas": ["è©³ç´°ãªåˆ†æã¯å®Œå…¨ç‰ˆã§ç¢ºèª"]
        }
        
        # é€ã‹ã—æƒ…å ±
        preview_content["watermark"] = {
            "text": "ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰ˆ - å®Œå…¨ç‰ˆã§å…¨å†…å®¹ãŒè¡¨ç¤ºã•ã‚Œã¾ã™",
            "position": "diagonal",
            "opacity": 0.3
        }
        
        return preview_content
    
    # === Evaluation Methods ===
    
    async def _evaluate_completeness(self, data: Dict[str, Any]) -> float:
        """å®Œå…¨æ€§è©•ä¾¡"""
        required_fields = [
            "company_info", "project_info", "business_plan", 
            "financial_plan", "implementation_schedule"
        ]
        
        filled_count = sum(1 for field in required_fields if data.get(field))
        base_score = (filled_count / len(required_fields)) * 70
        
        # è©³ç´°åº¦ãƒœãƒ¼ãƒŠã‚¹
        detail_bonus = 0
        for field in required_fields:
            content = str(data.get(field, ""))
            if len(content) > 500:  # ååˆ†ãªè©³ç´°
                detail_bonus += 6
            elif len(content) > 200:  # åŸºæœ¬çš„ãªè©³ç´°
                detail_bonus += 3
        
        return min(base_score + detail_bonus, 100)
    
    async def _evaluate_coherence(self, data: Dict[str, Any]) -> float:
        """ä¸€è²«æ€§è©•ä¾¡ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        # å®Ÿéš›ã«ã¯NLPåˆ†æã‚’è¡Œã†
        return 78.5
    
    async def _evaluate_persuasiveness(self, data: Dict[str, Any]) -> float:
        """èª¬å¾—åŠ›è©•ä¾¡ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        # å®Ÿéš›ã«ã¯æ–‡ç« åˆ†æã‚’è¡Œã†
        return 82.0
    
    async def _evaluate_technical_accuracy(self, data: Dict[str, Any]) -> float:
        """æŠ€è¡“çš„æ­£ç¢ºæ€§è©•ä¾¡ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        return 75.8
    
    async def _evaluate_innovation(self, data: Dict[str, Any]) -> float:
        """é©æ–°æ€§è©•ä¾¡ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        return 68.5
    
    async def _evaluate_feasibility(self, data: Dict[str, Any]) -> float:
        """å®Ÿç¾å¯èƒ½æ€§è©•ä¾¡ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        return 84.2
    
    def _predict_success_rate(
        self,
        overall_score: float,
        category_scores: Dict[str, float]
    ) -> float:
        """æˆåŠŸç‡äºˆæ¸¬"""
        
        # åŸºæœ¬æˆåŠŸç‡
        if overall_score >= 85:
            base_rate = 0.85
        elif overall_score >= 80:
            base_rate = 0.75
        elif overall_score >= 75:
            base_rate = 0.65
        elif overall_score >= 70:
            base_rate = 0.55
        elif overall_score >= 65:
            base_rate = 0.45
        else:
            base_rate = 0.30
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥èª¿æ•´
        innovation_factor = min(category_scores["innovation"] / 70, 1.2)
        feasibility_factor = min(category_scores["feasibility"] / 80, 1.1)
        
        adjusted_rate = base_rate * innovation_factor * feasibility_factor
        return min(adjusted_rate, 0.95)  # æœ€å¤§95%
    
    def _determine_quality_level(self, score: float) -> QualityLevel:
        """å“è³ªãƒ¬ãƒ™ãƒ«åˆ¤å®š"""
        if score >= 85:
            return QualityLevel.EXCELLENT
        elif score >= 70:
            return QualityLevel.GOOD
        elif score >= 55:
            return QualityLevel.FAIR
        else:
            return QualityLevel.NEEDS_IMPROVEMENT
    
    def _determine_purchase_urgency(self, quality_analysis: Dict[str, Any]) -> Optional[str]:
        """è³¼å…¥ç·Šæ€¥åº¦åˆ¤å®š"""
        score = quality_analysis["overall_score"]
        
        if score >= 85:
            return "ä»Šã™ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ç”³è«‹æº–å‚™ã‚’å®Œäº†ã•ã›ã¾ã—ã‚‡ã†ï¼"
        elif score >= 75:
            return "ã“ã®å“è³ªãªã‚‰æ¡æŠã®å¯èƒ½æ€§ãŒé«˜ã„ã§ã™ã€‚ãŠæ—©ã‚ã«ç”³è«‹ã‚’ã€‚"
        else:
            return None
    
    def _identify_strengths(self, category_scores: Dict[str, float]) -> List[str]:
        """å¼·ã¿ç‰¹å®š"""
        strengths = []
        for category, score in category_scores.items():
            if score >= 80:
                strengths.append(f"{category}ï¼ˆ{score:.1f}ç‚¹ï¼‰")
        return strengths
    
    def _identify_weaknesses(self, category_scores: Dict[str, float]) -> List[str]:
        """å¼±ç‚¹ç‰¹å®š"""
        weaknesses = []
        for category, score in category_scores.items():
            if score < 70:
                weaknesses.append(f"{category}ï¼ˆ{score:.1f}ç‚¹ï¼‰")
        return weaknesses
    
    def _get_quality_ranking(self, score: float) -> str:
        """å“è³ªãƒ©ãƒ³ã‚­ãƒ³ã‚°"""
        if score >= 90:
            return "Sç´šï¼ˆæœ€é«˜å“è³ªï¼‰"
        elif score >= 85:
            return "Aç´šï¼ˆå„ªç§€ï¼‰"
        elif score >= 75:
            return "Bç´šï¼ˆè‰¯å¥½ï¼‰"
        elif score >= 65:
            return "Cç´šï¼ˆæ¨™æº–ï¼‰"
        else:
            return "Dç´šï¼ˆè¦æ”¹å–„ï¼‰"
    
    def _generate_preview_id(self, data: Dict[str, Any]) -> str:
        """ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼IDç”Ÿæˆ"""
        data_str = json.dumps(data, sort_keys=True)
        hash_value = hashlib.md5(data_str.encode()).hexdigest()[:12]
        return f"enhanced_prev_{hash_value}"